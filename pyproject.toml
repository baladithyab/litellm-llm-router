[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "litellm-llmrouter"
version = "0.1.0"
description = "LiteLLM + LLMRouter Gateway - Production AI Gateway with ML-based routing"
readme = "README.md"
license = { text = "MIT" }
requires-python = ">=3.14"
dependencies = [
    # Core application framework
    "fastapi>=0.109.0",
    "pydantic>=2.5.0",
    "httpx>=0.26.0",
    # LiteLLM core (provides Router, logging, etc.)
    # Note: Using litellm without [proxy] extra due to strict pinned dependencies in proxy extra
    # that conflict with project requirements. Adding needed proxy deps individually below.
    "litellm>=1.81.3,<1.82.0",
    # APScheduler - required by litellm proxy for background scheduling
    "apscheduler>=3.10.0",
    # email-validator - required by pydantic.EmailStr (used by LiteLLM proxy SCIM)
    "email-validator>=2.0.0",
    # fastapi-sso - required by LiteLLM proxy SSO endpoints
    "fastapi-sso>=0.16.0",
    # websockets - required by LiteLLM proxy guardrails
    "websockets>=15.0.0",
    # backoff - required by LiteLLM proxy utils for retry logic
    "backoff>=2.0.0",
    # redis - required by LiteLLM for Redis caching
    "redis>=5.0.0",
    # A2A Protocol SDK (Agent-to-Agent communication)
    "a2a-sdk>=0.2.0",
    # Configuration and utilities
    "pyyaml>=6.0",
    "boto3>=1.42.32",
    "aiofiles>=23.0.0",
    "watchdog>=3.0.0",
    # Observability: OpenTelemetry core
    "prometheus-client>=0.24.1",
    "opentelemetry-api>=1.22.0",
    "opentelemetry-sdk>=1.22.0",
    "opentelemetry-exporter-otlp>=1.22.0",
    # OTEL instrumentation (required for observability module imports)
    "opentelemetry-instrumentation>=0.43b0",
    "opentelemetry-instrumentation-logging>=0.43b0",
    "python-multipart>=0.0.22",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.23.0",
    "hypothesis>=6.100.0",
    "black>=26.1.0",
    "ruff>=0.14.13",
    "mypy>=1.8.0",
]
# Database support (PostgreSQL with asyncpg and Prisma client for LiteLLM)
db = ["asyncpg>=0.29.0", "prisma>=0.13.0"]
# Full observability with all OTEL instrumentation
otel = [
    "opentelemetry-exporter-otlp-proto-grpc>=1.22.0",
    "opentelemetry-exporter-otlp-proto-http>=1.22.0",
    "opentelemetry-instrumentation-fastapi>=0.43b0",
    "opentelemetry-instrumentation-httpx>=0.43b0",
    "opentelemetry-instrumentation-requests>=0.43b0",
]
# Cloud provider SDKs (optional)
cloud = ["google-cloud-aiplatform>=1.134.0", "azure-identity>=1.15.0"]
# Callback integrations (langfuse, etc.)
callbacks = ["langfuse>=3.0.0"]
# KNN routing inference dependencies (sentence-transformers for embeddings)
knn = ["sentence-transformers>=5.2.0", "scikit-learn>=1.3.0"]
# Production extras (for Docker builds) - db, otel, cloud, callbacks, knn without dev tools
prod = ["litellm-llmrouter[db,otel,cloud,callbacks,knn]"]
# All optional dependencies (including dev tools)
all = ["litellm-llmrouter[dev,db,otel,cloud,knn]"]

[tool.setuptools.packages.find]
where = ["src"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
asyncio_mode = "auto"
addopts = "-v"

[tool.hypothesis]
max_examples = 100

[tool.black]
line-length = 88
target-version = ["py314"]

[tool.ruff]
line-length = 88
target-version = "py314"
exclude = ["reference/"]

[tool.mypy]
python_version = "3.14"
warn_return_any = true
warn_unused_configs = true

[dependency-groups]
dev = [
    "numpy>=2.2.6",
    "scikit-learn>=1.7.2",
    "pytest>=8.0.0",
    "pytest-asyncio>=0.23.0",
    "hypothesis>=6.100.0",
    "backoff>=2.0.0",
    "cryptography>=42.0.0",
    "orjson>=3.10.0",
    "ruff>=0.14.13",
]
