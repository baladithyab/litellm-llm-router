# LiteLLM + LLMRouter - Local Test Configuration
# Tests all features: A2A, MCP, Routing Strategies, Hot Reload
# Uses AWS Bedrock models (Claude 4.5 family + Nova 2 family)

# =============================================================================
# Model List - AWS Bedrock Models (IAM Profile auth)
# =============================================================================
model_list:
  # ---------------------------------------------------------------------------
  # Claude 4.5 Family (Anthropic via Bedrock)
  # ---------------------------------------------------------------------------
  - model_name: claude-4.5-sonnet
    litellm_params:
      model: bedrock/anthropic.claude-sonnet-4-5-20250929-v1:0
      aws_region_name: us-east-1
    model_info:
      id: claude-4.5-sonnet
      mode: chat
      description: "Claude 4.5 Sonnet - Latest and most capable Sonnet model"

  - model_name: claude-4.5-opus
    litellm_params:
      model: bedrock/anthropic.claude-opus-4-5-20251101-v1:0
      aws_region_name: us-east-1
    model_info:
      id: claude-4.5-opus
      mode: chat
      description: "Claude 4.5 Opus - Highest capability for complex tasks"

  - model_name: claude-4.5-haiku
    litellm_params:
      model: bedrock/anthropic.claude-haiku-4-5-20251001-v1:0
      aws_region_name: us-east-1
    model_info:
      id: claude-4.5-haiku
      mode: chat
      description: "Claude 4.5 Haiku - Fast and cost-effective"

  # Claude 4 Sonnet (previous generation)
  - model_name: claude-4-sonnet
    litellm_params:
      model: bedrock/anthropic.claude-sonnet-4-20250514-v1:0
      aws_region_name: us-east-1
    model_info:
      id: claude-4-sonnet
      mode: chat
      description: "Claude 4 Sonnet - Balanced performance"

  # ---------------------------------------------------------------------------
  # Amazon Nova 2 Family
  # ---------------------------------------------------------------------------
  - model_name: nova-2-lite
    litellm_params:
      model: bedrock/amazon.nova-2-lite-v1:0
      aws_region_name: us-east-1
    model_info:
      id: nova-2-lite
      mode: chat
      description: "Nova 2 Lite - Cost-effective with extended thinking"

  # ---------------------------------------------------------------------------
  # Amazon Nova Family (Original)
  # ---------------------------------------------------------------------------
  - model_name: nova-pro
    litellm_params:
      model: bedrock/amazon.nova-pro-v1:0
      aws_region_name: us-east-1
    model_info:
      id: nova-pro
      mode: chat
      description: "Nova Pro - Highly capable multimodal model"

  - model_name: nova-lite
    litellm_params:
      model: bedrock/amazon.nova-lite-v1:0
      aws_region_name: us-east-1
    model_info:
      id: nova-lite
      mode: chat
      description: "Nova Lite - Fast multimodal processing"

  - model_name: nova-micro
    litellm_params:
      model: bedrock/amazon.nova-micro-v1:0
      aws_region_name: us-east-1
    model_info:
      id: nova-micro
      mode: chat
      description: "Nova Micro - Ultra-fast text-only model"

# =============================================================================
# Router Settings - Test Multiple Strategies
# =============================================================================
router_settings:
  # Default to simple-shuffle, can be changed via API
  routing_strategy: simple-shuffle

  # LLMRouter strategy arguments
  routing_strategy_args:
    model_path: /app/models/router_model.pt
    llm_data_path: /app/config/llm_candidates.json
    hot_reload: true
    reload_interval: 30

  num_retries: 2
  retry_after: 5
  timeout: 300
  cache_responses: true

# =============================================================================
# General Settings
# =============================================================================
general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  # Disable database for testing (avoid Prisma issues)
  # database_url: os.environ/DATABASE_URL
  store_model_in_db: false
  # Enable detailed logging for testing
  # alerting: ["slack"]

# =============================================================================
# LiteLLM Settings
# =============================================================================
litellm_settings:
  cache: true
  cache_params:
    type: redis
    host: os.environ/REDIS_HOST
    port: os.environ/REDIS_PORT
    ttl: 300
  set_verbose: true
  drop_params: true
  # OpenTelemetry callbacks for Jaeger tracing
  success_callback: ["otel"]
  failure_callback: ["otel"]

# =============================================================================
# Observability Settings - Jaeger & MLflow
# =============================================================================
environment_variables:
  OTEL_EXPORTER_OTLP_ENDPOINT: "http://jaeger:4318"
  OTEL_SERVICE_NAME: "litellm-gateway"
  OTEL_TRACES_EXPORTER: "otlp"
  MLFLOW_TRACKING_URI: "http://mlflow:5050"

# =============================================================================
# MCP Servers Configuration
# =============================================================================
# MCP servers can be configured via API when MCP_GATEWAY_ENABLED=true
# The following servers are available via stdio transport in the mcp-proxy container:
#
# Available MCP Servers (stdio-based, no API keys required):
# - @anthropic-ai/server-filesystem: File system access for reading workspace files
# - @anthropic-ai/server-memory: Simple key-value memory for agents
#
# To add HTTP-based MCP servers dynamically:
# POST /mcp/servers with body:
# {
#   "server_id": "my-mcp-server",
#   "name": "My MCP Server",
#   "url": "http://localhost:8080/mcp",
#   "transport": "streamable_http"
# }

# =============================================================================
# A2A Agents - Test Configuration
# =============================================================================
# A2A agents are managed via API when A2A_GATEWAY_ENABLED=true
# Example agents that can be added via API:
# POST /a2a/agents with body:
# {
#   "agent_id": "my-agent",
#   "name": "My Agent",
#   "description": "A test agent",
#   "url": "http://localhost:9000/a2a",
#   "capabilities": ["chat", "code"]
# }

# =============================================================================
# Service Endpoints Reference (for testing)
# =============================================================================
# LiteLLM Gateway:     http://localhost:4010
# Jaeger UI:           http://localhost:16686
# MLflow UI:           http://localhost:5050
# MinIO Console:       http://localhost:9001 (admin: minioadmin/minioadmin)
# MinIO API:           http://localhost:9000
# MCP Proxy:           http://localhost:3100-3103 (for MCP server access)
