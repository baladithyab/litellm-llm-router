# LiteLLM + LLMRouter - MLOps Training/Finetuning Setup
# For training, evaluating, and deploying routing models

services:
  # ==========================================================================
  # MLflow - Experiment Tracking & Model Registry
  # Uses file-based backend for simplicity (no PostgreSQL required)
  # ==========================================================================
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.10.0
    container_name: llmrouter-mlflow
    command: >
      mlflow server
      --backend-store-uri sqlite:///mlflow/mlflow.db
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
      --port 5000
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-minioadmin}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-us-east-1}
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
    ports:
      - "5000:5000"
    volumes:
      - mlflow_data:/mlflow
    networks:
      - mlops-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==========================================================================
  # MinIO - S3-Compatible Object Storage (for local dev)
  # ==========================================================================
  minio:
    image: minio/minio:latest
    container_name: llmrouter-minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - mlops-network

  # ==========================================================================
  # LLMRouter Training Environment
  # ==========================================================================
  llmrouter-trainer:
    build:
      context: ../..
      dockerfile: examples/mlops/Dockerfile.trainer
    container_name: llmrouter-trainer
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-minioadmin}
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - WANDB_API_KEY=${WANDB_API_KEY:-}
      - HF_TOKEN=${HF_TOKEN:-}
    volumes:
      - ../../reference/LLMRouter:/app/LLMRouter:ro
      - ./data:/app/data
      - ./models:/app/models
      - ./configs:/app/configs
    command: ["tail", "-f", "/dev/null"]  # Keep alive for interactive use
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - mlops-network

  # ==========================================================================
  # Jupyter Lab for Interactive Development
  # ==========================================================================
  jupyter:
    build:
      context: ../..
      dockerfile: examples/mlops/Dockerfile.trainer
    container_name: llmrouter-jupyter
    command: >
      jupyter lab
      --ip=0.0.0.0
      --port=8888
      --no-browser
      --allow-root
      --NotebookApp.token=${JUPYTER_TOKEN:-llmrouter}
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-minioadmin}
    ports:
      - "8888:8888"
    volumes:
      - ../../reference/LLMRouter:/app/LLMRouter:ro
      - ./data:/app/data
      - ./models:/app/models
      - ./notebooks:/app/notebooks
    networks:
      - mlops-network

  # ==========================================================================
  # Model Deployment to Production Gateway
  # ==========================================================================
  model-deployer:
    build:
      context: ../..
      dockerfile: examples/mlops/Dockerfile.deployer
    container_name: llmrouter-deployer
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - TARGET_S3_BUCKET=${TARGET_S3_BUCKET:-llmrouter-models}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
    volumes:
      - ./models:/app/models
      - ./deploy-scripts:/app/scripts
    networks:
      - mlops-network

volumes:
  mlflow_data:
  minio_data:

networks:
  mlops-network:
    driver: bridge
